import json
import subprocess
from datetime import datetime, timedelta
from collections import Counter

def fetch_repos():
    result = subprocess.run(
        'gh repo list --limit 1000 --json name,isFork,createdAt,updatedAt,pushedAt,diskUsage,stargazerCount,forkCount,primaryLanguage,description,url,visibility',
        shell=True,
        capture_output=True,
        text=True
    )
    return json.loads(result.stdout)

def generate_report(repos):
    now = datetime.now()
    six_months_ago = (now - timedelta(days=180)).strftime('%Y-%m-%d')
    one_year_ago = (now - timedelta(days=365)).strftime('%Y-%m-%d')
    
    fork_repos = [r for r in repos if r.get('isFork', False)]
    orig_repos = [r for r in repos if not r.get('isFork', False)]
    
    report = []
    report.append("=" * 140)
    report.append("GitHub ä»“åº“åˆ†ææŠ¥å‘Š")
    report.append(f"åˆ†ææ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("=" * 140)
    report.append(f"æ€»ä»“åº“æ•°: {len(repos)}")
    report.append(f"  - Fork é¡¹ç›®: {len(fork_repos)}")
    report.append(f"  - åŸå§‹é¡¹ç›®: {len(orig_repos)}")
    report.append("")
    
    report.append("=" * 140)
    report.append("ğŸ“Š ä»“åº“ç±»å‹åˆ†å¸ƒ")
    report.append("=" * 140)
    
    visibility = Counter(r.get('visibility', 'unknown') for r in repos)
    report.append("å¯è§æ€§:")
    for v, count in visibility.most_common():
        report.append(f"  - {v}: {count} ä¸ª")
    
    report.append("")
    report.append("è¯­è¨€åˆ†å¸ƒ (Top 10):")
    langs = Counter((r.get('primaryLanguage') or {}).get('name', 'None') for r in repos)
    for lang, count in langs.most_common(10):
        report.append(f"  - {lang}: {count} ä¸ª")
    
    report.append("")
    report.append("=" * 140)
    report.append(f"ğŸ”´ Fork é¡¹ç›®è¯¦ç»†åˆ†æ ({len(fork_repos)} ä¸ª)")
    report.append("=" * 140)
    
    fork_old = [r for r in fork_repos if r['updatedAt'][:10] < six_months_ago]
    fork_recent = [r for r in fork_repos if r['updatedAt'][:10] >= six_months_ago]
    
    report.append("æ—¶é—´åˆ†å¸ƒ:")
    report.append(f"  - è¶…è¿‡6ä¸ªæœˆæœªæ›´æ–°: {len(fork_old)} ä¸ª")
    report.append(f"  - 6ä¸ªæœˆå†…æ›´æ–°: {len(fork_recent)} ä¸ª")
    
    report.append("")
    report.append("æ´»è·ƒåº¦åˆ†æ:")
    fork_active = [r for r in fork_repos if r.get('stargazerCount', 0) > 0 or r.get('forkCount', 0) > 0]
    fork_inactive = [r for r in fork_repos if r.get('stargazerCount', 0) == 0 and r.get('forkCount', 0) == 0]
    report.append(f"  - æœ‰ star æˆ– fork: {len(fork_active)} ä¸ª")
    report.append(f"  - æ—  star å’Œ fork: {len(fork_inactive)} ä¸ª")
    
    fork_storage = sum(r.get('diskUsage', 0) for r in fork_repos)
    report.append(f"  - Fork é¡¹ç›®æ€»å­˜å‚¨: {fork_storage / 1024:.2f} GB")
    
    report.append("")
    report.append("=" * 140)
    report.append(f"ğŸŸ¢ åŸå§‹é¡¹ç›®è¯¦ç»†åˆ†æ ({len(orig_repos)} ä¸ª)")
    report.append("=" * 140)
    
    orig_old = [r for r in orig_repos if r['updatedAt'][:10] < six_months_ago]
    orig_recent = [r for r in orig_repos if r['updatedAt'][:10] >= six_months_ago]
    
    report.append("æ—¶é—´åˆ†å¸ƒ:")
    report.append(f"  - è¶…è¿‡6ä¸ªæœˆæœªæ›´æ–°: {len(orig_old)} ä¸ª")
    report.append(f"  - 6ä¸ªæœˆå†…æ›´æ–°: {len(orig_recent)} ä¸ª")
    
    report.append("")
    report.append("æ´»è·ƒåº¦åˆ†æ:")
    orig_active = [r for r in orig_repos if r.get('stargazerCount', 0) > 0 or r.get('forkCount', 0) > 0]
    orig_inactive = [r for r in orig_repos if r.get('stargazerCount', 0) == 0 and r.get('forkCount', 0) == 0]
    report.append(f"  - æœ‰ star æˆ– fork: {len(orig_active)} ä¸ª")
    report.append(f"  - æ—  star å’Œ fork: {len(orig_inactive)} ä¸ª")
    
    orig_storage = sum(r.get('diskUsage', 0) for r in orig_repos)
    report.append(f"  - åŸå§‹é¡¹ç›®æ€»å­˜å‚¨: {orig_storage / 1024:.2f} GB")
    
    report.append("")
    report.append("=" * 140)
    report.append("ğŸ“ˆ åŸå§‹é¡¹ç›®åˆ—è¡¨ï¼ˆæŒ‰æ›´æ–°æ—¶é—´æ’åºï¼‰")
    report.append("=" * 140)
    report.append(f"{'é¡¹ç›®åç§°':<30} {'æ›´æ–°æ—¥æœŸ':<12} {'â­':<4} {'ğŸ´':<4} {'è¯­è¨€':<15} {'æè¿°'}")
    report.append("-" * 140)
    orig_sorted = sorted(orig_repos, key=lambda x: x['updatedAt'], reverse=True)
    for r in orig_sorted[:30]:
        updated = r['updatedAt'][:10]
        stars = r.get('stargazerCount', 0)
        forks_count = r.get('forkCount', 0)
        lang = (r.get('primaryLanguage') or {}).get('name', 'N/A')
        desc = (r.get('description') or 'N/A')[:40]
        report.append(f"{r['name']:<30} {updated:<12} {stars:<4} {forks_count:<4} {lang:<15} {desc}")
    
    report.append("")
    report.append("=" * 140)
    report.append("ğŸ’¾ å­˜å‚¨ç©ºé—´æ€»è§ˆ")
    report.append("=" * 140)
    total_storage = fork_storage + orig_storage
    report.append(f"  - Fork é¡¹ç›®: {fork_storage / 1024:.2f} GB")
    report.append(f"  - åŸå§‹é¡¹ç›®: {orig_storage / 1024:.2f} GB")
    report.append(f"  - æ€»è®¡: {total_storage / 1024:.2f} GB")
    
    report.append("")
    report.append("=" * 140)
    report.append("ğŸ¯ æ¸…ç†å»ºè®®")
    report.append("=" * 140)
    
    fork_cleanup_candidates = []
    for r in fork_repos:
        if r['updatedAt'][:10] < six_months_ago and r.get('stargazerCount', 0) == 0 and r.get('forkCount', 0) == 0:
            fork_cleanup_candidates.append(r)
    
    orig_cleanup_candidates = []
    for r in orig_repos:
        if r['updatedAt'][:10] < one_year_ago and r.get('stargazerCount', 0) == 0 and r.get('forkCount', 0) == 0 and r.get('diskUsage', 0) < 100:
            orig_cleanup_candidates.append(r)
    
    fork_storage_cleanup = sum(r.get('diskUsage', 0) for r in fork_cleanup_candidates)
    orig_storage_cleanup = sum(r.get('diskUsage', 0) for r in orig_cleanup_candidates)
    
    report.append("Fork é¡¹ç›®æ¸…ç†:")
    report.append(f"  - å¯åˆ é™¤æ•°é‡: {len(fork_cleanup_candidates)} ä¸ª (å æ€» fork: {len(fork_cleanup_candidates)/len(fork_repos)*100:.1f}%)")
    report.append(f"  - å¯é‡Šæ”¾ç©ºé—´: {fork_storage_cleanup / 1024:.2f} GB")
    
    report.append("")
    report.append("åŸå§‹é¡¹ç›®æ¸…ç†:")
    report.append(f"  - å¯åˆ é™¤æ•°é‡: {len(orig_cleanup_candidates)} ä¸ª (å æ€»åŸå§‹: {len(orig_cleanup_candidates)/len(orig_repos)*100:.1f}%)")
    report.append(f"  - å¯é‡Šæ”¾ç©ºé—´: {orig_storage_cleanup / 1024:.2f} GB")
    
    report.append("")
    report.append("æ€»è®¡æ¸…ç†:")
    report.append(f"  - å¯åˆ é™¤æ•°é‡: {len(fork_cleanup_candidates) + len(orig_cleanup_candidates)} ä¸ª")
    report.append(f"  - å¯é‡Šæ”¾ç©ºé—´: {(fork_storage_cleanup + orig_storage_cleanup) / 1024:.2f} GB")
    report.append(f"  - æ¸…ç†åå‰©ä½™: {len(repos) - len(fork_cleanup_candidates) - len(orig_cleanup_candidates)} ä¸ª")
    
    report.append("")
    report.append("=" * 140)
    report.append("âœ… æ´»è·ƒé¡¹ç›®æ¨èä¿ç•™")
    report.append("=" * 140)
    
    active_forks = [r for r in fork_repos if r['updatedAt'][:10] >= six_months_ago or r.get('stargazerCount', 0) > 0 or r.get('forkCount', 0) > 0]
    report.append(f"Fork é¡¹ç›®ï¼ˆ{len(active_forks)} ä¸ªï¼‰:")
    for r in active_forks[:10]:
        updated = r['updatedAt'][:10]
        stars = r.get('stargazerCount', 0)
        forks_count = r.get('forkCount', 0)
        lang = (r.get('primaryLanguage') or {}).get('name', 'N/A')
        report.append(f"  - {r['name']:<30} | æ›´æ–°: {updated} | â­{stars} | ğŸ´{forks_count} | {lang}")
    
    active_orig = [r for r in orig_repos if r['updatedAt'][:10] >= six_months_ago or r.get('stargazerCount', 0) > 0 or r.get('forkCount', 0) > 0]
    report.append("")
    report.append(f"åŸå§‹é¡¹ç›®ï¼ˆ{len(active_orig)} ä¸ªï¼‰:")
    for r in active_orig[:10]:
        updated = r['updatedAt'][:10]
        stars = r.get('stargazerCount', 0)
        forks_count = r.get('forkCount', 0)
        lang = (r.get('primaryLanguage') or {}).get('name', 'N/A')
        desc = (r.get('description') or 'N/A')[:35]
        report.append(f"  - {r['name']:<30} | æ›´æ–°: {updated} | â­{stars} | ğŸ´{forks_count} | {desc}")
    
    return '\n'.join(report)

def save_report(report, output_file):
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

def main():
    print("ğŸ” æ­£åœ¨è·å– GitHub ä»“åº“æ•°æ®...")
    repos = fetch_repos()
    print(f"âœ… æˆåŠŸè·å– {len(repos)} ä¸ªä»“åº“")
    
    print("ğŸ“Š æ­£åœ¨åˆ†æä»“åº“æ•°æ®...")
    report = generate_report(repos)
    
    output_file = 'repos_analysis_report.txt'
    print("ğŸ“ æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    save_report(report, output_file)
    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ åˆ†ææ‘˜è¦")
    print("=" * 60)
    print(f"  æ€»ä»“åº“æ•°: {len(repos)}")
    fork_repos = [r for r in repos if r.get('isFork', False)]
    orig_repos = [r for r in repos if not r.get('isFork', False)]
    print(f"  Fork é¡¹ç›®: {len(fork_repos)}")
    print(f"  åŸå§‹é¡¹ç›®: {len(orig_repos)}")
    print(f"  æŠ¥å‘Šæ–‡ä»¶: {output_file}")

if __name__ == '__main__':
    main()
