#!/usr/bin/env python3
"""
æ–‡æ¡£è¦†ç›–ç‡æ£€æŸ¥å·¥å…·
æ£€æŸ¥ä»£ç ä¸­çš„å‡½æ•°ã€ç±»ã€æ¨¡å—çš„æ–‡æ¡£å®Œæ•´æ€§
æ”¯æŒ Pythonã€JavaScript/TypeScript ç­‰å¤šç§è¯­è¨€
"""

import ast
import os
import re
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any


class DocCoverageAnalyzer:
    """æ–‡æ¡£è¦†ç›–ç‡åˆ†æå™¨"""

    def __init__(self, project_path: str = "."):
        self.project_path = Path(project_path)
        self.results = {
            'summary': {},
            'files': [],
            'undocumented': [],
            'quality_score': 0
        }

    def analyze(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„æ–‡æ¡£è¦†ç›–ç‡åˆ†æ"""
        print("ğŸ” å¼€å§‹åˆ†ææ–‡æ¡£è¦†ç›–ç‡...")

        # æŸ¥æ‰¾æ‰€æœ‰éœ€è¦åˆ†æçš„æ–‡ä»¶
        files = self._find_source_files()
        print(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæºæ–‡ä»¶")

        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        for file_path in files:
            file_result = self._analyze_file(file_path)
            if file_result:
                self.results['files'].append(file_result)

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        self._calculate_summary()

        # è®¡ç®—è´¨é‡è¯„åˆ†
        self._calculate_quality_score()

        return self.results

    def _find_source_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰æºä»£ç æ–‡ä»¶"""
        file_patterns = [
            '**/*.py',
            '**/*.js',
            '**/*.ts',
            '**/*.jsx',
            '**/*.tsx',
        ]

        exclude_dirs = {
            'node_modules', 'venv', '.venv', 'env',
            '__pycache__', '.git', 'dist', 'build',
            'tests', 'test', '.tox', '.pytest_cache',
            'vendor', 'third_party', '.next', '.nuxt'
        }

        files = []
        for pattern in file_patterns:
            for file_path in self.project_path.rglob(pattern):
                # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤ç›®å½•ä¸­
                if any(exclude_dir in file_path.parts for exclude_dir in exclude_dirs):
                    continue
                files.append(file_path)

        return files

    def _analyze_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„æ–‡æ¡£è¦†ç›–ç‡"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if file_path.suffix == '.py':
                return self._analyze_python_file(file_path, content)
            elif file_path.suffix in ['.js', '.ts', '.jsx', '.tsx']:
                return self._analyze_javascript_file(file_path, content)
            else:
                return None

        except Exception as e:
            print(f"âš ï¸  åˆ†ææ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return None

    def _analyze_python_file(self, file_path: Path, content: str) -> Dict[str, Any]:
        """åˆ†æ Python æ–‡ä»¶çš„æ–‡æ¡£è¦†ç›–ç‡"""
        try:
            tree = ast.parse(content, filename=str(file_path))
        except SyntaxError:
            return None

        file_result = {
            'path': str(file_path.relative_to(self.project_path)),
            'type': 'python',
            'module_doc': self._get_module_docstring(tree),
            'classes': [],
            'functions': [],
            'total_elements': 0,
            'documented_elements': 0,
            'coverage': 0.0
        }

        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                class_info = self._analyze_class(node)
                file_result['classes'].append(class_info)
                file_result['total_elements'] += 1
                if class_info['has_doc']:
                    file_result['documented_elements'] += 1

            elif isinstance(node, ast.FunctionDef):
                # åªåˆ†ææ¨¡å—çº§åˆ«çš„å‡½æ•°ï¼ˆä¸åœ¨ç±»ä¸­çš„å‡½æ•°ï¼‰
                is_method = False
                for parent in ast.walk(tree):
                    if isinstance(parent, ast.ClassDef) and hasattr(parent, 'body'):
                        # å®‰å…¨åœ°æ£€æŸ¥ node æ˜¯å¦åœ¨ parent.body ä¸­
                        try:
                            if node in parent.body:
                                is_method = True
                                break
                        except (TypeError, AttributeError):
                            # parent.body å¯èƒ½ä¸æ˜¯å¯è¿­ä»£çš„ï¼Œè·³è¿‡
                            continue

                if not is_method:
                    func_info = self._analyze_function(node)
                    file_result['functions'].append(func_info)
                    file_result['total_elements'] += 1
                    if func_info['has_doc']:
                        file_result['documented_elements'] += 1

        # è®¡ç®—è¦†ç›–ç‡
        if file_result['total_elements'] > 0:
            file_result['coverage'] = (
                file_result['documented_elements'] / file_result['total_elements'] * 100
            )

        # è®°å½•æœªæ–‡æ¡£åŒ–çš„å…ƒç´ 
        self._record_undocumented(file_result)

        return file_result

    def _analyze_class(self, node: ast.ClassDef) -> Dict[str, Any]:
        """åˆ†æç±»çš„æ–‡æ¡£"""
        class_info = {
            'name': node.name,
            'line': node.lineno,
            'is_public': not node.name.startswith('_'),
            'has_doc': ast.get_docstring(node) is not None,
            'docstring': ast.get_docstring(node),
            'methods': []
        }

        for item in node.body:
            if isinstance(item, ast.FunctionDef):
                method_info = self._analyze_function(item, is_method=True)
                class_info['methods'].append(method_info)

        return class_info

    def _analyze_function(self, node: ast.FunctionDef, is_method: bool = False) -> Dict[str, Any]:
        """åˆ†æå‡½æ•°çš„æ–‡æ¡£"""
        docstring = ast.get_docstring(node)

        func_info = {
            'name': node.name,
            'line': node.lineno,
            'is_public': not node.name.startswith('_'),
            'is_method': is_method,
            'has_doc': docstring is not None,
            'docstring': docstring,
            'doc_quality': self._assess_doc_quality(docstring) if docstring else 'missing'
        }

        return func_info

    def _get_module_docstring(self, tree: ast.AST) -> Dict[str, Any]:
        """è·å–æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²"""
        docstring = ast.get_docstring(tree)
        return {
            'has_doc': docstring is not None,
            'docstring': docstring,
            'quality': self._assess_doc_quality(docstring) if docstring else 'missing'
        }

    def _assess_doc_quality(self, docstring: str) -> str:
        """è¯„ä¼°æ–‡æ¡£è´¨é‡"""
        if not docstring:
            return 'missing'

        # ç§»é™¤ç©ºç™½å­—ç¬¦
        clean_doc = re.sub(r'\s+', ' ', docstring.strip())

        # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæˆ–åªæ˜¯å ä½ç¬¦
        if len(clean_doc) < 10:
            return 'poor'
        if clean_doc.lower() in ['todo', 'fix me', 'tbd', 'placeholder']:
            return 'poor'

        # æ£€æŸ¥æ–‡æ¡£å®Œæ•´æ€§
        has_description = len(clean_doc) > 20
        has_args = 'arg' in clean_doc.lower() or 'param' in clean_doc.lower()
        has_return = 'return' in clean_doc.lower() or 'returns' in clean_doc.lower()
        has_raises = 'raise' in clean_doc.lower() or 'exception' in clean_doc.lower()

        if has_description and has_args and has_return:
            return 'complete'
        elif has_description:
            return 'good'
        else:
            return 'basic'

    def _analyze_javascript_file(self, file_path: Path, content: str) -> Dict[str, Any]:
        """åˆ†æ JavaScript/TypeScript æ–‡ä»¶çš„æ–‡æ¡£è¦†ç›–ç‡"""
        file_result = {
            'path': str(file_path.relative_to(self.project_path)),
            'type': 'javascript',
            'functions': [],
            'total_elements': 0,
            'documented_elements': 0,
            'coverage': 0.0
        }

        # æŸ¥æ‰¾æ‰€æœ‰å‡½æ•°å®šä¹‰
        # åŒ¹é… function name() å’Œ const name = () => ç­‰å½¢å¼
        function_patterns = [
            r'function\s+(\w+)\s*\(',
            r'const\s+(\w+)\s*=\s*(?:async\s*)?\([^)]*\)\s*=>',
            r'(\w+)\s*:\s*(?:async\s*)?function',
            r'(\w+)\s*\([^)]*\)\s*{',  # æ–¹æ³•å®šä¹‰
            r'export\s+(?:const|function)\s+(\w+)',
        ]

        lines = content.split('\n')

        for line_num, line in enumerate(lines, 1):
            # è·³è¿‡æ³¨é‡Šè¡Œ
            stripped = line.strip()
            if stripped.startswith('//') or stripped.startswith('*'):
                continue

            for pattern in function_patterns:
                match = re.search(pattern, line)
                if match:
                    func_name = match.group(1)
                    is_public = not func_name.startswith('_')

                    # æ£€æŸ¥å‰ä¸€è¡Œæ˜¯å¦æœ‰ JSDoc æ³¨é‡Š
                    has_jsdoc = False
                    if line_num > 1:
                        prev_line = lines[line_num - 2].strip()
                        has_jsdoc = prev_line.startswith('*') or prev_line.startswith('/**')

                    func_info = {
                        'name': func_name,
                        'line': line_num,
                        'is_public': is_public,
                        'has_doc': has_jsdoc,
                        'doc_quality': 'good' if has_jsdoc else 'missing'
                    }

                    file_result['functions'].append(func_info)
                    file_result['total_elements'] += 1
                    if has_jsdoc:
                        file_result['documented_elements'] += 1
                    break

        # è®¡ç®—è¦†ç›–ç‡
        if file_result['total_elements'] > 0:
            file_result['coverage'] = (
                file_result['documented_elements'] / file_result['total_elements'] * 100
            )

        # è®°å½•æœªæ–‡æ¡£åŒ–çš„å…ƒç´ 
        self._record_undocumented(file_result)

        return file_result

    def _record_undocumented(self, file_result: Dict[str, Any]):
        """è®°å½•æœªæ–‡æ¡£åŒ–çš„å…¬å…± API"""
        file_path = file_result['path']

        # æ£€æŸ¥æ¨¡å—æ–‡æ¡£
        if file_result.get('type') == 'python':
            if not file_result.get('module_doc', {}).get('has_doc', False):
                self.results['undocumented'].append({
                    'type': 'module',
                    'path': file_path,
                    'name': file_path
                })

        # æ£€æŸ¥ç±»æ–‡æ¡£
        for cls in file_result.get('classes', []):
            if cls['is_public'] and not cls['has_doc']:
                self.results['undocumented'].append({
                    'type': 'class',
                    'path': file_path,
                    'name': cls['name'],
                    'line': cls['line']
                })

        # æ£€æŸ¥å‡½æ•°/æ–¹æ³•æ–‡æ¡£
        for func in file_result.get('functions', []):
            if func['is_public'] and not func['has_doc']:
                self.results['undocumented'].append({
                    'type': 'function',
                    'path': file_path,
                    'name': func['name'],
                    'line': func['line']
                })

    def _calculate_summary(self):
        """è®¡ç®—æ€»ä½“ç»Ÿè®¡"""
        total_files = len(self.results['files'])
        total_elements = sum(f.get('total_elements', 0) for f in self.results['files'])
        total_documented = sum(f.get('documented_elements', 0) for f in self.results['files'])

        overall_coverage = (total_documented / total_elements * 100) if total_elements > 0 else 0

        # æŒ‰ç±»å‹ç»Ÿè®¡
        python_files = [f for f in self.results['files'] if f.get('type') == 'python']
        js_files = [f for f in self.results['files'] if f.get('type') == 'javascript']

        self.results['summary'] = {
            'total_files': total_files,
            'python_files': len(python_files),
            'javascript_files': len(js_files),
            'total_elements': total_elements,
            'documented_elements': total_documented,
            'undocumented_elements': total_elements - total_documented,
            'overall_coverage': overall_coverage,
            'public_api_missing': len([u for u in self.results['undocumented'] if u.get('is_public', True)])
        }

    def _calculate_quality_score(self):
        """è®¡ç®—æ–‡æ¡£è´¨é‡è¯„åˆ†"""
        if not self.results['files']:
            self.results['quality_score'] = 0
            return

        # ç»Ÿè®¡æ–‡æ¡£è´¨é‡åˆ†å¸ƒ
        quality_counts = {'complete': 0, 'good': 0, 'basic': 0, 'poor': 0, 'missing': 0}

        for file_result in self.results['files']:
            for cls in file_result.get('classes', []):
                if cls.get('doc_quality'):
                    quality_counts[cls['doc_quality']] = quality_counts.get(cls['doc_quality'], 0) + 1

                for method in cls.get('methods', []):
                    if method.get('doc_quality'):
                        quality_counts[method['doc_quality']] = quality_counts.get(method['doc_quality'], 0) + 1

            for func in file_result.get('functions', []):
                if func.get('doc_quality'):
                    quality_counts[func['doc_quality']] = quality_counts.get(func['doc_quality'], 0) + 1

        # è®¡ç®—åŠ æƒè¯„åˆ†
        total = sum(quality_counts.values())
        if total == 0:
            self.results['quality_score'] = 0
            return

        score = (
            quality_counts.get('complete', 0) * 100 +
            quality_counts.get('good', 0) * 80 +
            quality_counts.get('basic', 0) * 50 +
            quality_counts.get('poor', 0) * 20
        ) / total

        self.results['quality_score'] = round(score, 2)
        self.results['quality_distribution'] = quality_counts


def generate_report(analyzer: DocCoverageAnalyzer, output_file: str = 'doc_coverage_report.txt'):
    """ç”Ÿæˆæ–‡æ¡£è¦†ç›–ç‡æŠ¥å‘Š"""
    results = analyzer.results
    summary = results['summary']

    report = []
    report.append("=" * 140)
    report.append("ğŸ“š æ–‡æ¡£è¦†ç›–ç‡åˆ†ææŠ¥å‘Š")
    report.append(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("=" * 140)
    report.append("")

    # æ€»ä½“ç»Ÿè®¡
    report.append("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
    report.append("-" * 140)
    report.append(f"  åˆ†ææ–‡ä»¶æ€»æ•°: {summary['total_files']}")
    report.append(f"    - Python æ–‡ä»¶: {summary['python_files']}")
    report.append(f"    - JavaScript/TypeScript æ–‡ä»¶: {summary['javascript_files']}")
    report.append(f"  ä»£ç å…ƒç´ æ€»æ•°: {summary['total_elements']}")
    report.append(f"    - å·²æ–‡æ¡£åŒ–: {summary['documented_elements']}")
    report.append(f"    - æœªæ–‡æ¡£åŒ–: {summary['undocumented_elements']}")
    report.append(f"  æ€»ä½“è¦†ç›–ç‡: {summary['overall_coverage']:.2f}%")
    report.append(f"  æ–‡æ¡£è´¨é‡è¯„åˆ†: {results['quality_score']:.1f}/100")
    report.append("")

    # è´¨é‡è¯„åˆ†è¯´æ˜
    quality_score = results['quality_score']
    if quality_score >= 80:
        quality_level = "ä¼˜ç§€ âœ…"
    elif quality_score >= 60:
        quality_level = "è‰¯å¥½ ğŸŸ¡"
    elif quality_score >= 40:
        quality_level = "ä¸€èˆ¬ ğŸŸ "
    else:
        quality_level = "éœ€è¦æ”¹è¿› ğŸ”´"

    report.append(f"  æ–‡æ¡£è´¨é‡ç­‰çº§: {quality_level}")
    report.append("")

    # è´¨é‡åˆ†å¸ƒ
    if 'quality_distribution' in results:
        report.append("ğŸ“ˆ æ–‡æ¡£è´¨é‡åˆ†å¸ƒ")
        report.append("-" * 140)
        dist = results['quality_distribution']
        report.append(f"  å®Œæ•´æ–‡æ¡£ (complete): {dist.get('complete', 0)}")
        report.append(f"  è‰¯å¥½æ–‡æ¡£ (good): {dist.get('good', 0)}")
        report.append(f"  åŸºç¡€æ–‡æ¡£ (basic): {dist.get('basic', 0)}")
        report.append(f"  è¾ƒå·®æ–‡æ¡£ (poor): {dist.get('poor', 0)}")
        report.append(f"  ç¼ºå¤±æ–‡æ¡£ (missing): {dist.get('missing', 0)}")
        report.append("")

    # å„æ–‡ä»¶è¯¦ç»†æƒ…å†µ
    report.append("ğŸ“ å„æ–‡ä»¶æ–‡æ¡£è¦†ç›–ç‡")
    report.append("-" * 140)
    report.append(f"{'æ–‡ä»¶è·¯å¾„':<50} {'æ€»å…ƒç´ ':<8} {'å·²æ–‡æ¡£åŒ–':<10} {'è¦†ç›–ç‡':<10} {'ç±»å‹'}")
    report.append("-" * 140)

    # æŒ‰è¦†ç›–ç‡æ’åº
    sorted_files = sorted(results['files'], key=lambda x: x.get('coverage', 0))
    for file_result in sorted_files:
        path = file_result['path'][:48]
        total = file_result.get('total_elements', 0)
        documented = file_result.get('documented_elements', 0)
        coverage = file_result.get('coverage', 0)
        file_type = file_result.get('type', 'unknown')

        # æ ¹æ®è¦†ç›–ç‡æ·»åŠ æ ‡è®°
        if coverage >= 80:
            emoji = "âœ…"
        elif coverage >= 50:
            emoji = "ğŸŸ¡"
        else:
            emoji = "ğŸ”´"

        report.append(f"{path:<50} {total:<8} {documented:<10} {coverage:>6.2f}% {emoji}  {file_type}")

    report.append("")

    # æœªæ–‡æ¡£åŒ–çš„å…¬å…± API
    if results['undocumented']:
        report.append("âš ï¸  ç¼ºå¤±æ–‡æ¡£çš„å…¬å…± API")
        report.append("-" * 140)
        report.append(f"å…±æœ‰ {len(results['undocumented'])} ä¸ªå…¬å…± API ç¼ºå°‘æ–‡æ¡£")
        report.append("")

        # æŒ‰æ–‡ä»¶åˆ†ç»„æ˜¾ç¤º
        undocumented_by_file = {}
        for item in results['undocumented']:
            file_path = item['path']
            if file_path not in undocumented_by_file:
                undocumented_by_file[file_path] = []
            undocumented_by_file[file_path].append(item)

        # æ˜¾ç¤ºå‰ 10 ä¸ªæ–‡ä»¶
        for file_path, items in list(undocumented_by_file.items())[:10]:
            report.append(f"  ğŸ“„ {file_path}")
            for item in items[:5]:  # æ¯ä¸ªæ–‡ä»¶æ˜¾ç¤ºå‰ 5 ä¸ª
                item_type = item['type']
                name = item['name']
                line = item.get('line', '?')
                report.append(f"    - {item_type}: {name} (è¡Œ {line})")

            if len(items) > 5:
                report.append(f"    ... è¿˜æœ‰ {len(items) - 5} ä¸ª")
            report.append("")

        if len(undocumented_by_file) > 10:
            report.append(f"  ... è¿˜æœ‰ {len(undocumented_by_file) - 10} ä¸ªæ–‡ä»¶åŒ…å«æœªæ–‡æ¡£åŒ–çš„ API")
            report.append("")
    else:
        report.append("âœ… æ‰€æœ‰å…¬å…± API éƒ½æœ‰æ–‡æ¡£ï¼")
        report.append("")

    # æ”¹è¿›å»ºè®®
    report.append("ğŸ’¡ æ”¹è¿›å»ºè®®")
    report.append("-" * 140)

    if summary['overall_coverage'] < 50:
        report.append("  1. ä¼˜å…ˆä¸ºå…¬å…± API æ·»åŠ æ–‡æ¡£")
        report.append("  2. è‡³å°‘æ·»åŠ å‡½æ•°/ç±»çš„åŸºæœ¬æè¿°")
        report.append("  3. ä½¿ç”¨æ–‡æ¡£å­—ç¬¦ä¸²æ¨¡æ¿è§„èŒƒæ ¼å¼")
    elif summary['overall_coverage'] < 80:
        report.append("  1. å®Œå–„ç°æœ‰æ–‡æ¡£ï¼Œæ·»åŠ å‚æ•°å’Œè¿”å›å€¼è¯´æ˜")
        report.append("  2. ä¸ºå¤æ‚å‡½æ•°æ·»åŠ ä½¿ç”¨ç¤ºä¾‹")
        report.append("  3. è¡¥å……å¼‚å¸¸å’Œé”™è¯¯æƒ…å†µçš„è¯´æ˜")
    else:
        report.append("  1. ç»§ç»­ä¿æŒæ–‡æ¡£è´¨é‡")
        report.append("  2. å®šæœŸå®¡æŸ¥å’Œæ›´æ–°æ–‡æ¡£")
        report.append("  3. è€ƒè™‘æ·»åŠ æ›´å¤šä½¿ç”¨ç¤ºä¾‹")

    report.append("")
    report.append("=" * 140)
    report.append("ğŸ“‹ Python æ–‡æ¡£å­—ç¬¦ä¸²å»ºè®®æ ¼å¼")
    report.append("=" * 140)
    report.append("""
def function_name(param1, param2):
    '''
    å‡½æ•°çš„ç®€çŸ­æè¿°ï¼ˆä¸€å¥è¯ï¼‰

    è¯¦ç»†æè¿°å‡½æ•°çš„åŠŸèƒ½ã€ç”¨é€”å’Œè¡Œä¸ºã€‚

    Args:
        param1 (type): å‚æ•°1çš„æè¿°
        param2 (type): å‚æ•°2çš„æè¿°

    Returns:
        type: è¿”å›å€¼çš„æè¿°

    Raises:
        ExceptionType: å¼‚å¸¸æƒ…å†µçš„æè¿°

    Examples:
        >>> function_name('value1', 'value2')
        'result'
    '''
    pass
    """)

    report.append("=" * 140)
    report.append("ğŸ“‹ JavaScript JSDoc å»ºè®®æ ¼å¼")
    report.append("=" * 140)
    report.append("""
/**
 * å‡½æ•°çš„ç®€çŸ­æè¿°
 *
 * è¯¦ç»†æè¿°å‡½æ•°çš„åŠŸèƒ½ã€ç”¨é€”å’Œè¡Œä¸ºã€‚
 *
 * @param {type} param1 - å‚æ•°1çš„æè¿°
 * @param {type} param2 - å‚æ•°2çš„æè¿°
 * @returns {type} è¿”å›å€¼çš„æè¿°
 * @throws {Error} å¼‚å¸¸æƒ…å†µçš„æè¿°
 *
 * @example
 * // ä½¿ç”¨ç¤ºä¾‹
 * functionName('value1', 'value2');
 */
function functionName(param1, param2) {
    // å®ç°
}
    """)

    report_content = '\n'.join(report)

    # ä¿å­˜æŠ¥å‘Š
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report_content)

    # åŒæ—¶ç”Ÿæˆ JSON æŠ¥å‘Š
    json_file = output_file.replace('.txt', '.json')
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    return report_content


def main():
    """ä¸»å‡½æ•°"""
    import sys

    # è·å–é¡¹ç›®è·¯å¾„
    project_path = sys.argv[1] if len(sys.argv) > 1 else "."

    print("ğŸ“š æ–‡æ¡£è¦†ç›–ç‡æ£€æŸ¥å·¥å…·")
    print("=" * 60)
    print(f"ğŸ” åˆ†æè·¯å¾„: {os.path.abspath(project_path)}")
    print()

    try:
        # åˆ›å»ºåˆ†æå™¨å¹¶æ‰§è¡Œåˆ†æ
        analyzer = DocCoverageAnalyzer(project_path)
        results = analyzer.analyze()

        # ç”ŸæˆæŠ¥å‘Š
        print("ğŸ“Š æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
        report = generate_report(analyzer)

        # è¾“å‡ºæ‘˜è¦
        summary = results['summary']
        print()
        print("=" * 60)
        print("âœ… åˆ†æå®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“ åˆ†ææ–‡ä»¶: {summary['total_files']}")
        print(f"ğŸ“ ä»£ç å…ƒç´ : {summary['total_elements']}")
        print(f"âœ… å·²æ–‡æ¡£åŒ–: {summary['documented_elements']}")
        print(f"âŒ æœªæ–‡æ¡£åŒ–: {summary['undocumented_elements']}")
        print(f"ğŸ“Š è¦†ç›–ç‡: {summary['overall_coverage']:.2f}%")
        print(f"â­ è´¨é‡è¯„åˆ†: {results['quality_score']:.1f}/100")
        print()
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°:")
        print(f"   - doc_coverage_report.txt")
        print(f"   - doc_coverage_report.json")
        print()

        # æ ¹æ®è¦†ç›–ç‡ç»™å‡ºè¯„ä¼°
        if summary['overall_coverage'] >= 80:
            print("ğŸ‰ æ–‡æ¡£è¦†ç›–ç‡ä¼˜ç§€ï¼ç»§ç»­ä¿æŒï¼")
        elif summary['overall_coverage'] >= 50:
            print("ğŸŸ¡ æ–‡æ¡£è¦†ç›–ç‡è‰¯å¥½ï¼Œè¿˜æœ‰æå‡ç©ºé—´ã€‚")
        else:
            print("âš ï¸  æ–‡æ¡£è¦†ç›–ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜å…ˆä¸ºå…¬å…± API æ·»åŠ æ–‡æ¡£ã€‚")

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
